{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A98oqeOVo9QK"
   },
   "source": [
    "# Transfer Learning Baseline - Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pLi7vHrk2AC"
   },
   "source": [
    "Build up baseline image set by generating reconstruct images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4aVf1WaWkti4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bochao/maskgit\n"
     ]
    }
   ],
   "source": [
    "%cd /home/bochao/maskgit\n",
    "import cv2\n",
    "import albumentations\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from flax import serialization\n",
    "# from flax import optim\n",
    "import optax\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import maskgit\n",
    "from maskgit.utils import visualize_images, read_image_from_url, restore_from_path, draw_image_with_bbox, Bbox\n",
    "from maskgit.inference import ImageNet_class_conditional_generator\n",
    "from maskgit.nets import vqgan_tokenizer, maskgit_transformer\n",
    "from maskgit.configs import maskgit_class_cond_config\n",
    "from maskgit.libml import losses, mask_schedule, parallel_decode\n",
    "\n",
    "# categories = [\n",
    "#  'jasmine', 'phlox', 'leucan', 'cherry',\n",
    "#  'viola', 'lily', 'appleTree', 'snowdrop',\n",
    "#  'perennial', 'blackberry', 'strawberry', 'nankingcherry',\n",
    "#  'bellflower'\n",
    "#]\n",
    "category = 'jasmine'\n",
    "TRAIN_DATA_DIR = '/home/bochao/flowers/' + category\n",
    "TOKENIZER_CKPT = '/home/bochao/checkpoints/vqvae_ckpt_v1/vqvae_epoch19'\n",
    "OUTPUT_DIR = '/home/bochao/results/tokenizer_baseline'\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# define our crop schema for train imgs\n",
    "rescaler = albumentations.SmallestMaxSize(max_size=256)\n",
    "cropper = albumentations.CenterCrop(height=256, width=256)\n",
    "preprocessor = albumentations.Compose([rescaler, cropper])\n",
    "\n",
    "def read_image(img_path):\n",
    "    img = cv2.imread(img_path).astype(np.uint8)\n",
    "    img = preprocessor(image=img)[\"image\"]\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32, saturate=False)\n",
    "    return img\n",
    "\n",
    "# data loader with crop\n",
    "class Dataloader(tf.keras.utils.Sequence): #\n",
    "    def __init__(self, data_dir, batch_size):\n",
    "        self.train_imgs_path = glob.glob(data_dir + '/*.png')\n",
    "        self.train_imgs = []\n",
    "        self.counter = 0\n",
    "        self.num_imgs = len(self.train_imgs_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.im_size = 256\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return np.ceil( self.num_imgs / self.batch_size).astype(int)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        while(len(self.train_imgs) < self.batch_size):\n",
    "            img = read_image(self.train_imgs_path[self.counter])\n",
    "            self.train_imgs.append(img)\n",
    "            self.counter = (self.counter+1) % self.num_imgs\n",
    "        batch = self.train_imgs[0:self.batch_size]\n",
    "        self.train_imgs = self.train_imgs[self.batch_size:]\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNbMEAlLlvfY"
   },
   "source": [
    "Define tokenizer and generate reconstruct images based on train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cD-LPU1jmkQz"
   },
   "outputs": [],
   "source": [
    "# configurations\n",
    "maskgit_cf = maskgit_class_cond_config.get_config()\n",
    "maskgit_cf.image_size = IMG_SIZE\n",
    "maskgit_cf.eval_batch_size = 8\n",
    "batch_size = 2\n",
    "\n",
    "# dataloader\n",
    "train_dataset = Dataloader(TRAIN_DATA_DIR, batch_size)\n",
    "# tokenizer\n",
    "tokenizer = vqgan_tokenizer.VQVAE(config=maskgit_cf, dtype=jnp.float32, train=False)\n",
    "# load checkpoint\n",
    "tokenizer_variables = restore_from_path(TOKENIZER_CKPT)\n",
    "counter = 0\n",
    "\n",
    "for batch in train_dataset:\n",
    "    input_dict = {\n",
    "        'image': batch\n",
    "    }\n",
    "    quantized, result_dict = tokenizer.apply(tokenizer_variables, input_dict, method=tokenizer.encode, mutable=False)\n",
    "    # decode\n",
    "    reconstructed_imgs = tokenizer.apply(tokenizer_variables, quantized, method=tokenizer.decode, mutable=False)\n",
    "    for i in range(batch_size):\n",
    "        img = tf.clip_by_value(reconstructed_imgs[i], 0.0, 1.0)\n",
    "        result_img = tf.image.convert_image_dtype(img, tf.uint8).numpy()\n",
    "        tf.keras.utils.save_img(OUTPUT_DIR + f'/{counter}.png', x=result_img, data_format='channels_last')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Pc01YOPpCzc"
   },
   "source": [
    "# RQ-VAE tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLfxgbE-pH6N"
   },
   "source": [
    "Load RQ-VAE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOO48ZZJpNiW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09dpLO27pOFK"
   },
   "source": [
    "Generate reconstructed images using RQ-VAE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j3MI_ThpXhV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tokenizer_Improvement.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
