{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15J9OmqyR1bz"
   },
   "source": [
    "Install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5KAUWjTKRxdD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bochao\n",
      "Requirement already satisfied: tensorflow-gan in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: tensorflow-probability>=0.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gan) (0.14.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gan) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (1.21.5)\n",
      "Requirement already satisfied: gast>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.5.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.1.6)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (2.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/bochao/\n",
    "!pip install tensorflow-gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lvI3-hCR74i"
   },
   "source": [
    "Compute Inception Score using tensorflow.gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2_-SKayISDba"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "import functools\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.python.ops import array_ops\n",
    "# pip install tensorflow-gan\n",
    "import tensorflow_gan as tfgan\n",
    "session=tf.compat.v1.InteractiveSession()\n",
    "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
    "BATCH_SIZE = 1\n",
    "INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'\n",
    "INCEPTION_OUTPUT = 'logits'\n",
    "\n",
    "# Run images through Inception.\n",
    "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')\n",
    "def inception_logits(images = inception_images, num_splits = 1):\n",
    "    images = tf.transpose(images, [0, 2, 3, 1])\n",
    "    size = 299\n",
    "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
    "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
    "    logits = tf.map_fn(\n",
    "        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_OUTPUT, True),\n",
    "        elems = array_ops.stack(generated_images_list),\n",
    "        parallel_iterations = 8,\n",
    "        back_prop = False,\n",
    "        swap_memory = True,\n",
    "        name = 'RunClassifier')\n",
    "    logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
    "    return logits\n",
    "\n",
    "logits=inception_logits()\n",
    "\n",
    "def get_inception_probs(inps):\n",
    "    session=tf.get_default_session()\n",
    "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
    "    preds = np.zeros([inps.shape[0], 1000], dtype = np.float32)\n",
    "    for i in range(n_batches):\n",
    "        inp = (inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] / 255. * 2 - 1).astype(np.float32)\n",
    "        preds[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(logits,{inception_images: inp})[:, :1000]\n",
    "    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
    "    return preds\n",
    "\n",
    "def preds2score(preds, splits=10):\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
    "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "        kl = np.mean(np.sum(kl, 1))\n",
    "        scores.append(np.exp(kl))\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def get_inception_score(images, splits=10):\n",
    "    assert(type(images) == np.ndarray)\n",
    "    assert(len(images.shape) == 4)\n",
    "    assert(images.shape[1] == 3)\n",
    "    assert(np.min(images[0]) >= 0 and np.max(images[0]) > 10), 'Image values should be in the range [0, 255]'\n",
    "    print('Calculating Inception Score with %i images in %i splits' % (images.shape[0], splits))\n",
    "    start_time=time.time()\n",
    "    preds = get_inception_probs(images)\n",
    "    mean, std = preds2score(preds, splits)\n",
    "    print('Inception Score calculation time: %f s' % (time.time() - start_time))\n",
    "    return mean, std  # Reference values: 11.38 for 50000 CIFAR-10 training set images, or mean=11.31, std=0.10 if in 10 splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JO_DvF8SIJS"
   },
   "source": [
    "Compute FID using tensorflow.gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "J5pJG8wmSOmy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py:914: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  structure[0], [func(*x) for x in entries],\n",
      "/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "import functools\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.python.ops import array_ops\n",
    "# pip install tensorflow-gan\n",
    "import tensorflow_gan as tfgan\n",
    "\n",
    "session=tf.compat.v1.InteractiveSession()\n",
    "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Run images through Inception.\n",
    "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')\n",
    "activations1 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations1')\n",
    "activations2 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations2')\n",
    "fcd = tfgan.eval.frechet_classifier_distance_from_activations(activations1, activations2)\n",
    "\n",
    "INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'\n",
    "INCEPTION_FINAL_POOL = 'pool_3'\n",
    "\n",
    "def inception_activations(images = inception_images, num_splits = 1):\n",
    "    images = tf.transpose(images, [0, 2, 3, 1])\n",
    "    size = 299\n",
    "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
    "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
    "    activations = tf.map_fn(\n",
    "        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_FINAL_POOL, True),\n",
    "        elems = array_ops.stack(generated_images_list),\n",
    "        parallel_iterations = 1,\n",
    "        back_prop = False,\n",
    "        swap_memory = True,\n",
    "        name = 'RunClassifier')\n",
    "    activations = array_ops.concat(array_ops.unstack(activations), 0)\n",
    "    return activations\n",
    "\n",
    "activations =inception_activations()\n",
    "\n",
    "def get_inception_activations(inps):\n",
    "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
    "    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)\n",
    "    for i in range(n_batches):\n",
    "        inp = (inps[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] / 255. * 2 - 1).astype(np.float32)\n",
    "        act[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(activations, feed_dict = {inception_images: inp})\n",
    "    return act\n",
    "\n",
    "def activations2distance(act1, act2):\n",
    "    return session.run(fcd, feed_dict = {activations1: act1, activations2: act2})\n",
    "        \n",
    "def get_fid(images1, images2):\n",
    "    session=tf.get_default_session()\n",
    "    assert(type(images1) == np.ndarray)\n",
    "    assert(len(images1.shape) == 4)\n",
    "    assert(images1.shape[1] == 3)\n",
    "    assert(np.min(images1[0]) >= 0 and np.max(images1[0]) > 10), 'Image values should be in the range [0, 255]'\n",
    "    assert(type(images2) == np.ndarray)\n",
    "    assert(len(images2.shape) == 4)\n",
    "    assert(images2.shape[1] == 3)\n",
    "    assert(np.min(images2[0]) >= 0 and np.max(images2[0]) > 10), 'Image values should be in the range [0, 255]'\n",
    "    assert(images1.shape == images2.shape), 'The two numpy arrays must have the same shape'\n",
    "    print('Calculating FID with %i images from each distribution' % (images1.shape[0]))\n",
    "    start_time = time.time()\n",
    "    act1 = get_inception_activations(images1)\n",
    "    act2 = get_inception_activations(images2)\n",
    "    fid = activations2distance(act1, act2)\n",
    "    print('FID calculation time: %f s' % (time.time() - start_time))\n",
    "    return fid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU5l2FUKSRhy"
   },
   "source": [
    "Evaluate IS and FID of the generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "# categories = [\n",
    "#  'jasmine', 'phlox', 'leucan', 'cherry',\n",
    "#  'viola', 'lily', 'appleTree', 'snowdrop',\n",
    "#  'perennial', 'blackberry', 'strawberry', 'nankingcherry',\n",
    "#  'bellflower'\n",
    "#]\n",
    "# Change these path to test IS and FID for different images\n",
    "category = 'jasmine'\n",
    "TRAIN_DATA_DIR = '/home/bochao/flowers/' + category\n",
    "GEN_DATA_DIR = '/home/bochao/results/' + category\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# define our crop schema for train imgs\n",
    "rescaler = albumentations.SmallestMaxSize(max_size=256)\n",
    "cropper = albumentations.CenterCrop(height=256, width=256)\n",
    "preprocessor = albumentations.Compose([rescaler, cropper])\n",
    "\n",
    "def read_gen_imgs(dir_path):\n",
    "    img_paths = glob.glob(dir_path + '/*.png')\n",
    "    n = len(img_paths)\n",
    "    gen_imgs = np.zeros([n, IMG_SIZE, IMG_SIZE, 3], dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        path = img_paths[i]\n",
    "        gen_imgs[i] = cv2.imread(path).astype(np.uint8)\n",
    "    return gen_imgs   \n",
    "\n",
    "def read_train_imgs(dir_path):\n",
    "    img_paths = glob.glob(dir_path + '/*.png')\n",
    "    n = len(img_paths)\n",
    "    train_imgs = np.zeros([n, IMG_SIZE, IMG_SIZE, 3], dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        path = img_paths[i]\n",
    "        img = cv2.imread(path).astype(np.uint8)\n",
    "        img = preprocessor(image=img)[\"image\"]\n",
    "        assert (IMG_SIZE, IMG_SIZE, 3) == img.shape\n",
    "        tf.keras.utils.save_img(f'/home/bochao/crop_flowers/jasmine/{i}.png', x=img, data_format='channels_last')\n",
    "        train_imgs[i] = img\n",
    "    return train_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ew8dE38-SXqy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score with 50 images in 10 splits\n",
      "Inception Score calculation time: 1.812045 s\n",
      "Inception Score: mean=1.4658, std=0.1932\n"
     ]
    }
   ],
   "source": [
    "# modify path to train directory and generate image directory\n",
    "# to find the IS and FID scores\n",
    "\n",
    "# Baseline tokenizer IS, FID scores\n",
    "TRAIN_DATA_DIR = '/home/bochao/flowers/jasmine'\n",
    "GEN_DATA_DIR = '/home/bochao/results/tokenizer_baseline'\n",
    "\n",
    "# read train and generated images\n",
    "train_imgs = read_train_imgs(TRAIN_DATA_DIR)\n",
    "gen_imgs = read_gen_imgs(GEN_DATA_DIR)\n",
    "\n",
    "# IS scores\n",
    "is_mean, is_std = get_inception_score(gen_imgs.transpose([0,3,1,2]), splits=10)\n",
    "print(f'Inception Score: mean={is_mean:.4f}, std={is_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FID with 50 images from each distribution\n",
      "FID calculation time: 8.389242 s\n",
      "FID: 216.2836\n"
     ]
    }
   ],
   "source": [
    "# FID scores\n",
    "fid_score = get_fid(gen_imgs.transpose([0,3,1,2]), train_imgs.transpose([0,3,1,2]))\n",
    "print(f'FID: {fid_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score with 1000 images in 10 splits\n",
      "Inception Score calculation time: 14.996258 s\n",
      "Inception Score: mean=2.2504, std=0.0649\n"
     ]
    }
   ],
   "source": [
    "# Baseline MaskGIT IS, FID scores\n",
    "TRAIN_DATA_DIR = '/home/bochao/flowers/jasmine'\n",
    "GEN_DATA_DIR = '/home/bochao/results/transformer_baseline'\n",
    "\n",
    "# read train and generated images\n",
    "train_imgs = read_train_imgs(TRAIN_DATA_DIR)\n",
    "gen_imgs = read_gen_imgs(GEN_DATA_DIR)\n",
    "\n",
    "# IS scores\n",
    "is_mean, is_std = get_inception_score(gen_imgs.transpose([0,3,1,2]), splits=10)\n",
    "print(f'Inception Score: mean={is_mean:.4f}, std={is_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:04<00:00,  4.25it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "FID:  234.46482060506816\n"
     ]
    }
   ],
   "source": [
    "# FID scores\n",
    "!python -m pytorch_fid /home/bochao/results/transformer_baseline /home/bochao/crop_flowers/jasmine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IS_FID_evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
